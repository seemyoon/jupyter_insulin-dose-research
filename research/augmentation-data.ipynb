{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data preparation",
   "id": "68c8fae3b8ee014a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.pipeline  import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import seaborn as sns\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "# import smogn\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler, ADASYN, BorderlineSMOTE, SVMSMOTE"
   ],
   "id": "1e755d044b3e4971",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Set path to folder with data",
   "id": "b4c32b910bffee35"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "folder_path = Path('../diabetes_project/cleaned_data/HUPA-UCM-cleaned_data')",
   "id": "863ed22f3666bc29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load patients info and check duplicates",
   "id": "dad394fd87a10a4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check folder and file existence\n",
    "if not os.path.exists(folder_path):\n",
    "    raise FileNotFoundError(f\"Directory {folder_path} does not exist.\")"
   ],
   "id": "831bfe7932cc79b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load time series data and combine and preprocess data",
   "id": "f1b5ccc44de61b3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_files = [folder_path / f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "data_list = []\n",
    "for file in all_files:\n",
    "    temp_data = pd.read_csv(file, delimiter=';')\n",
    "    temp_data['person_id'] = file.stem\n",
    "    data_list.append(temp_data)\n",
    "\n",
    "df = pd.concat(data_list, ignore_index=True).drop_duplicates()"
   ],
   "id": "c3bc8b605317796c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Convert time and handle errors",
   "id": "a4e80c851d84189a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
    "df = df.dropna(subset=['time'])\n",
    "df['minute'] = df['time'].dt.minute\n",
    "df['hour_of_day'] = df['time'].dt.hour\n",
    "df['month'] = df['time'].dt.month\n",
    "df['day'] = df['time'].dt.day.clip(1, df['time'].dt.days_in_month)\n",
    "df.columns"
   ],
   "id": "4cc8ba3aac52dbed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Anomaly checks",
   "id": "8eaf13538fb9fea2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Heart rate check\n",
    "df = df[(df['heart_rate'] > 40) & (df['heart_rate'] < 200)]\n",
    "# Glucose range check\n",
    "df = df[(df['glucose'] >= 0) & (df['glucose'] <= 500)]\n",
    "# Minute range check\n",
    "df = df[(df['minute'] >= 0) & (df['minute'] <= 59)]\n",
    "# Hour of day range check\n",
    "df = df[(df['hour_of_day'] >= 0) & (df['hour_of_day'] <= 23)]\n",
    "# Month range check\n",
    "df = df[(df['month'] >= 1) & (df['month'] <= 12)]\n",
    "# Age range check"
   ],
   "id": "6dee41bdf71b3d15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check target variable",
   "id": "4ed78c5f1892abbc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if df['basal_rate'].isna().any():\n",
    "    raise ValueError(\"Target variable 'basal_rate' contains missing values!\")"
   ],
   "id": "b1db41207a016ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Analyse of data",
   "id": "6245bd5507029585"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head(8)",
   "id": "5e0f7dfa7da1797",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(df.drop(columns=['bolus_volume_delivered', 'person_id']).corr(), annot=True, fmt='.2f')"
   ],
   "id": "30b6a3a5a29bacb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.describe()",
   "id": "62880701bdeebc59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Histogram/Chart for all columns (total amount of HUPA-UCM-full_data)\n",
    "counts = df.count()\n",
    "counts"
   ],
   "id": "35b3a8ab02f12316",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df.hist(bins=25, figsize=(30, 30), color='green')\n",
    "plt.show()"
   ],
   "id": "e2cfbe93aa51ea8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define features",
   "id": "169e6d163e3bec7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "features = [\n",
    "    'glucose', 'calories', 'heart_rate', 'steps',\n",
    "    'bolus_volume_delivered', 'carb_input', 'minute',\n",
    "    'hour_of_day', 'month', 'day',\n",
    "]\n",
    "print(features)"
   ],
   "id": "4a1b72a4ce9c3b0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = df[features]\n",
    "y = df['basal_rate']"
   ],
   "id": "d47e272a5570b823",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SMOGN",
   "id": "a192ffaeefe6aa44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# df_smogn = smogn.smoter(\n",
    "#     HUPA-UCM-full_data=df.sample(n=50000, random_state=42).reset_index(drop=True),\n",
    "#     # HUPA-UCM-full_data=df, # Original HUPA-UCM-full_data frame with HUPA-UCM-full_data\n",
    "#     y='basal_rate', # Target variable (what to balance)\n",
    "#     k=5, # Number of neighbors to generate new points\n",
    "#     pert=0.02, # Percentage of noise added to new HUPA-UCM-full_data\n",
    "#     samp_method=\"balance\", # Balancing method (\"balance\" or \"extreme\")\n",
    "#     under_samp=True # Whether to further reduce the number of frequent values\n",
    "# )\n",
    "#\n",
    "# X_smogn = df_smogn[features]\n",
    "# y_smogn = df_smogn['basal_rate']"
   ],
   "id": "efc7aede62d46131",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# reset_index(drop=True) is like renumbering the pages in a new book. Without it, SMOGN can get \"lost\" and crash with an error. This is standard practice when working with subselects in Pandas.\n",
    "# we set df.sample(n=50000, random_state=42).reset_index(drop=True) instead of df"
   ],
   "id": "1886a5c3be35c4bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SMOTER",
   "id": "527c171d4ee67cac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def smoter(X, y, tE, o=100, k=5):\n",
    "    y_median = np.median(y)\n",
    "    rare_low = np.where((y < y_median) & (y > tE))[0]\n",
    "    rare_high = np.where((y > y_median) & (y > tE))[0]\n",
    "\n",
    "    rare_indices = np.concatenate((rare_low, rare_high))\n",
    "    if len(rare_indices) == 0:\n",
    "        return X, y\n",
    "\n",
    "    X_rare = X.iloc[rare_indices]\n",
    "    y_rare = y.iloc[rare_indices]\n",
    "\n",
    "    knn = NearestNeighbors(n_neighbors=k)\n",
    "    knn.fit(X_rare)\n",
    "\n",
    "    new_X = []\n",
    "    new_y = []\n",
    "\n",
    "    for i in range(len(X_rare)):\n",
    "        neighbors = knn.kneighbors([X_rare.iloc[i]], return_distance=False)[0]\n",
    "        for _ in range(o // 100):\n",
    "            neighbor_idx = np.random.choice(neighbors[1:])\n",
    "            alpha = np.random.rand()\n",
    "            synthetic_x = X_rare.iloc[i] + alpha * (X_rare.iloc[neighbor_idx] - X_rare.iloc[i])\n",
    "            d1 = np.linalg.norm(X_rare.iloc[i] - synthetic_x)\n",
    "            d2 = np.linalg.norm(X_rare.iloc[neighbor_idx] - synthetic_x)\n",
    "            synthetic_y = (d2 * y_rare.iloc[i] + d1 * y_rare.iloc[neighbor_idx]) / (d1 + d2)\n",
    "\n",
    "            new_X.append(synthetic_x)\n",
    "            new_y.append(synthetic_y)\n",
    "\n",
    "    X_synthetic = pd.DataFrame(new_X, columns=X.columns)\n",
    "    y_synthetic = pd.Series(new_y)\n",
    "\n",
    "    X_resampled = pd.concat([X, X_synthetic], ignore_index=True)\n",
    "    y_resampled = pd.concat([y, y_synthetic], ignore_index=True)\n",
    "\n",
    "    return X_resampled, y_resampled"
   ],
   "id": "2ae28f9e0922baaa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # This method is used to train the normalizer on training HUPA-UCM-full_data.\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_final, y_final = smoter(pd.DataFrame(X_train_scaled, columns=features), y_train, tE=np.percentile(y_train, 10))"
   ],
   "id": "42ad31e7f0c35fd9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Over-sampling samplers (DON'T WORK FOR REGRESSION)",
   "id": "8254e23076bcf606"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# SMOTE is applied after splitting the HUPA-UCM-full_data because it should only operate on the training set to avoid HUPA-UCM-full_data leakage.\n",
    "# In SMOGN, oversampling is first applied on the entire dataset and then splitting. This is because SMOGN uses a strategy that takes into account the distribution of the target variable, and applying it before splitting helps create a more balanced dataset.\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# smote = SMOTE(sampling_strategy='auto', k_neighbors=5, random_state=42)\n",
    "# smote = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "# smote = KMeansSMOTE(sampling_strategy='auto', k_neighbors=5, random_state=42)\n",
    "# smote = ADASYN(sampling_strategy='auto', random_state=42)\n",
    "# smote = SVMSMOTE(sampling_strategy='auto', random_state=42)\n",
    "# smote = BorderlineSMOTE(sampling_strategy='auto', random_state=42)\n",
    "smote = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_smote)  # This method is used to train the normalizer on training HUPA-UCM-full_data.\n",
    "X_test_scaled = scaler.transform(X_test)  # This is important because the test HUPA-UCM-full_data should be scaled in the same way as the training HUPA-UCM-full_data to avoid HUPA-UCM-full_data leakage.\n",
    "\n",
    "# fit should be used when you want to calculate parameters (like mean and standard deviation) on the HUPA-UCM-full_data to use for scaling.\n",
    "# transform is used to scale the HUPA-UCM-full_data using the parameters that have already been calculated.\n",
    "# fit_transform is just a convenience form that first calculates the parameters and then scales the HUPA-UCM-full_data on the training HUPA-UCM-full_data.\n",
    "# transform on X_test is used to transform the test HUPA-UCM-full_data by the same parameters that were calculated on the training HUPA-UCM-full_data."
   ],
   "id": "93a304ee64a152b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Now calculating summary statistics for each of the columns",
   "id": "724580b7f674ee97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "summary = df[features].describe().transpose()",
   "id": "5eff4c0e390d9ebb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Predict dose",
   "id": "a2c5861721c8fa06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)",
   "id": "86ccdca1d0a65b77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Predict dose (SMOGN)",
   "id": "9b1796f1c1b0e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# X_train, X_test, y_train, y_test = train_test_split(X_smogn, y_smogn, test_size=0.2, random_state=42)",
   "id": "ab1d43f2a2ba710c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data scaling",
   "id": "bbd6320c13da074c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)"
   ],
   "id": "d894d896f3dc4e74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SMOGN (DT)",
   "id": "8f364ea4a0f572d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = DecisionTreeRegressor(max_depth=22, min_samples_leaf=2, min_samples_split=2, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "mse_rounded = round(mse, 6)\n",
    "r2_rounded = round(r2, 6)\n",
    "mae_rounded = round(mae, 6)\n",
    "\n",
    "# Output results\n",
    "print(f'Decision Tree. Mean Squared Error: {mse_rounded}')\n",
    "print(f'Decision Tree. R²: {r2_rounded}')\n",
    "print(f'Decision Tree. Mean Absolute Error: {mae_rounded}')"
   ],
   "id": "4b1a4fe0cead5d1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SMOGN (RF)",
   "id": "572bae45c115bf1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = RandomForestRegressor(n_estimators=200, min_samples_split=2, min_samples_leaf=1, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "mse_rounded = round(mse, 6)\n",
    "r2_rounded = round(r2, 6)\n",
    "mae_rounded = round(mae, 6)\n",
    "\n",
    "# Output results\n",
    "print(f'Random Forest. Mean Squared Error: {mse_rounded}')\n",
    "print(f'Random Forest. R²: {r2_rounded}')\n",
    "print(f'Random Forest. Mean Absolute Error: {mae_rounded}')"
   ],
   "id": "2f9834376a1a095e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SMOGN (XGB)",
   "id": "938ac6f3ee355009"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = XGBRegressor(n_estimators=800, subsample=1.0, reg_lambda=1, reg_alpha=0.1, max_depth=14, learning_rate=0.05,\n",
    "                     gamma=0, colsample_bytree=0.6)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "mse_rounded = round(mse, 6)\n",
    "r2_rounded = round(r2, 6)\n",
    "mae_rounded = round(mae, 6)\n",
    "\n",
    "# Output results\n",
    "print(f'XGB. Mean Squared Error: {mse_rounded}')\n",
    "print(f'XGB. R²: {r2_rounded}')\n",
    "print(f'XGB. Mean Absolute Error: {mae_rounded}')"
   ],
   "id": "f0a1888c409e3def",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SMOGN (LR)",
   "id": "1b65ff678554df13"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "mse_rounded = round(mse, 6)\n",
    "r2_rounded = round(r2, 6)\n",
    "mae_rounded = round(mae, 6)\n",
    "\n",
    "# Output results\n",
    "print(f'Random Forest. Mean Squared Error: {mse_rounded}')\n",
    "print(f'Random Forest. R²: {r2_rounded}')\n",
    "print(f'Random Forest. Mean Absolute Error: {mae_rounded}')"
   ],
   "id": "eed878c00b3325e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SMOGN (KNN)",
   "id": "31611331ca4cbea3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = KNeighborsRegressor(weights='distance', n_neighbors=7, metric='manhattan')\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "mse_rounded = round(mse, 6)\n",
    "r2_rounded = round(r2, 6)\n",
    "mae_rounded = round(mae, 6)\n",
    "\n",
    "# Output results\n",
    "print(f'KNN. Mean Squared Error: {mse_rounded}')\n",
    "print(f'KNN. R²: {r2_rounded}')\n",
    "print(f'KNN. Mean Absolute Error: {mae_rounded}')"
   ],
   "id": "6d77031e3af063fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# GMM",
   "id": "67cbd3f68116b3b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Augmentation (10% of original size for large dataset)\n",
    "gmm = GaussianMixture(n_components=3, random_state=42)\n",
    "gmm.fit(X_train_scaled)\n",
    "percentage_quan_sample = 0.1\n",
    "X_augmented, _ = gmm.sample(n_samples=int(percentage_quan_sample * len(X_train_scaled)))  # 10% of the original volume\n",
    "\n",
    "# Data Merging\n",
    "X_final = np.vstack([X_train_scaled, X_augmented])\n",
    "y_final = np.concatenate([y_train, y_train[:len(X_augmented)]])"
   ],
   "id": "2364ca910340f2d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### RF",
   "id": "84e6874aac5158b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = RandomForestRegressor(n_estimators=200, min_samples_split=2, min_samples_leaf=1, random_state=42)\n",
    "model.fit(X_final, y_final)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "mse_rounded = round(mse, 6)\n",
    "r2_rounded = round(r2, 6)\n",
    "mae_rounded = round(mae, 6)\n",
    "\n",
    "# Output results\n",
    "print(f'Random Forest. Mean Squared Error: {mse_rounded}')\n",
    "print(f'Random Forest. R²: {r2_rounded}')\n",
    "print(f'Random Forest. Mean Absolute Error: {mae_rounded}')"
   ],
   "id": "e41faaacd02aa40b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### DT",
   "id": "8b033f670e0f2406"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Pipeline is a short construction instead of below diabetes_project\n",
    "# pipeline = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('model', DecisionTreeRegressor(max_depth=22, min_samples_leaf=2, min_samples_split=2, random_state=42))\n",
    "# ])\n",
    "model = DecisionTreeRegressor(max_depth=22, min_samples_leaf=2, min_samples_split=2, random_state=42)\n",
    "model.fit(X_final, y_final)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "mse_rounded = round(mse, 6)\n",
    "r2_rounded = round(r2, 6)\n",
    "mae_rounded = round(mae, 6)\n",
    "\n",
    "# Output results\n",
    "print(f'Decision Tree. Mean Squared Error: {mse_rounded}')\n",
    "print(f'Decision Tree. R²: {r2_rounded}')\n",
    "print(f'Decision Tree. Mean Absolute Error: {mae_rounded}')"
   ],
   "id": "34cce9ab5bcca765",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### KNN",
   "id": "a70d2735102ab304"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = KNeighborsRegressor(weights='distance', n_neighbors=7, metric='manhattan')\n",
    "model.fit(X_final, y_final)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "mse_rounded = round(mse, 6)\n",
    "r2_rounded = round(r2, 6)\n",
    "mae_rounded = round(mae, 6)\n",
    "\n",
    "# Output results\n",
    "print(f'KNN. Mean Squared Error: {mse_rounded}')\n",
    "print(f'KNN. R²: {r2_rounded}')\n",
    "print(f'KNN. Mean Absolute Error: {mae_rounded}')"
   ],
   "id": "ecf4271b3f7804ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### XGB",
   "id": "279c819f3bfce78d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = XGBRegressor(n_estimators=800, subsample=1.0, reg_lambda=1, reg_alpha=0.1, max_depth=14, learning_rate=0.05,\n",
    "                     gamma=0, colsample_bytree=0.6)\n",
    "model.fit(X_final, y_final)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "mse_rounded = round(mse, 6)\n",
    "r2_rounded = round(r2, 6)\n",
    "mae_rounded = round(mae, 6)\n",
    "\n",
    "# Output results\n",
    "print(f'XGB. Mean Squared Error: {mse_rounded}')\n",
    "print(f'XGB. R²: {r2_rounded}')\n",
    "print(f'XGB. Mean Absolute Error: {mae_rounded}')"
   ],
   "id": "a1fb3121e7a360f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### LR",
   "id": "6d3954a594a08b73"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_final, y_final)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "mse_rounded = round(mse, 6)\n",
    "r2_rounded = round(r2, 6)\n",
    "mae_rounded = round(mae, 6)\n",
    "\n",
    "# Output results\n",
    "print(f'Random Forest. Mean Squared Error: {mse_rounded}')\n",
    "print(f'Random Forest. R²: {r2_rounded}')\n",
    "print(f'Random Forest. Mean Absolute Error: {mae_rounded}')"
   ],
   "id": "cc3cee078235a15f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Augmentation data (FOMA)",
   "id": "e0d7a44ee22a221a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# def foma_augmentation(X, y, alpha=0.1, n_samples=100):\n",
    "#     idx = np.random.choice(len(X), size=n_samples, replace=True)\n",
    "#\n",
    "#     X_selected = X[idx]\n",
    "#     y_selected = y.iloc[idx].values\n",
    "#\n",
    "#     noise = alpha * np.random.randn(*X_selected.shape)\n",
    "#     X_augmented = X_selected + noise\n",
    "#\n",
    "#     y_augmented = y_selected + alpha * np.random.randn(n_samples)\n",
    "#\n",
    "#     return np.vstack([X, X_augmented]), np.hstack([y, y_augmented])\n",
    "#\n",
    "#\n",
    "# X_train_aug, y_train_aug = foma_augmentation(X_train_scaled, y_train)\n",
    "#\n",
    "# model = DecisionTreeRegressor(max_depth=22, min_samples_leaf=2, min_samples_split=2, random_state=42)\n",
    "# model.fit(X_train_aug, y_train_aug)\n",
    "#\n",
    "# y_pred = model.predict(X_test_scaled)\n",
    "#\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "#\n",
    "# print(f'Decision Tree. Mean Squared Error: {round(mse, 6)}')\n",
    "# print(f'Decision Tree. R²: {round(r2, 6)}')\n",
    "# print(f'Decision Tree. Mean Absolute Error: {round(mae, 6)}')"
   ],
   "id": "261d70540e379c71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Augmentation data (FOMA)",
   "id": "91f63ba6874d0e22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# def foma_augmentation(X, y, alpha=0.1, n_samples=100):\n",
    "#     idx = np.random.choice(len(X), size=n_samples, replace=True)\n",
    "#\n",
    "#     X_selected = X[idx]\n",
    "#     y_selected = y.iloc[idx].values\n",
    "#\n",
    "#     noise = alpha * np.random.randn(*X_selected.shape)\n",
    "#     X_augmented = X_selected + noise\n",
    "#\n",
    "#     y_augmented = y_selected + alpha * np.random.randn(n_samples)\n",
    "#\n",
    "#     return np.vstack([X, X_augmented]), np.hstack([y, y_augmented])\n",
    "#\n",
    "#\n",
    "# X_train_aug, y_train_aug = foma_augmentation(X_train_scaled, y_train)\n",
    "#\n",
    "# model = RandomForestRegressor(n_estimators=200, min_samples_split=2, min_samples_leaf=1, random_state=42)\n",
    "# model.fit(X_train_aug, y_train_aug)\n",
    "#\n",
    "# y_pred = model.predict(X_test_scaled)\n",
    "#\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "#\n",
    "# print(f'Random Forest. Mean Squared Error: {round(mse, 6)}')\n",
    "# print(f'Random Forest. R²: {round(r2, 6)}')\n",
    "# print(f'Random Forest. Mean Absolute Error: {round(mae, 6)}')"
   ],
   "id": "d859847055da940",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### DT model creation, training and evaluation (with augmentation)",
   "id": "6abc89c40c177b01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# model = DecisionTreeRegressor(max_depth=22, min_samples_leaf=2, min_samples_split=2, random_state=42)\n",
    "# model.fit(X_train_scaled, y_train)\n",
    "# # Prediction and model evaluation\n",
    "# y_pred = model.predict(X_test_scaled)\n",
    "#\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "#\n",
    "# mse_rounded = round(mse, 6)\n",
    "# r2_rounded = round(r2, 6)\n",
    "# mae_rounded = round(mae, 6)\n",
    "#\n",
    "# # Output results\n",
    "# print(f'Decision Tree. Mean Squared Error: {mse_rounded}')\n",
    "# print(f'Decision Tree. R²: {r2_rounded}')\n",
    "# print(f'Decision Tree. Mean Absolute Error: {mae_rounded}')"
   ],
   "id": "dfba1d497142ada2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Without augmentation",
   "id": "69b5af38c25d922e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## DT",
   "id": "5ccddb6a5c31b4f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# model = DecisionTreeRegressor(max_depth=22, min_samples_leaf=2, min_samples_split=2, random_state=42)\n",
    "# model.fit(X_train_scaled, y_train)\n",
    "# y_pred = model.predict(X_test_scaled)\n",
    "#\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "#\n",
    "# mse_rounded = round(mse, 6)\n",
    "# r2_rounded = round(r2, 6)\n",
    "# mae_rounded = round(mae, 6)\n",
    "#\n",
    "# # Output results\n",
    "# print(f'Decision Tree. Mean Squared Error: {mse_rounded}')\n",
    "# print(f'Decision Tree. R²: {r2_rounded}')\n",
    "# print(f'Decision Tree. Mean Absolute Error: {mae_rounded}')"
   ],
   "id": "760bdfd4308084f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### RF",
   "id": "2b690c5b4706a946"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# model = RandomForestRegressor(n_estimators=200, min_samples_split=2, min_samples_leaf=1, random_state=42)\n",
    "# model.fit(X_train_scaled, y_train)\n",
    "#\n",
    "# # Prediction and model evaluation\n",
    "# y_pred = model.predict(X_test_scaled)\n",
    "#\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "#\n",
    "# mse_rounded = round(mse, 6)\n",
    "# r2_rounded = round(r2, 6)\n",
    "# mae_rounded = round(mae, 6)\n",
    "#\n",
    "# # Output results\n",
    "# print(f'Random Forest. Mean Squared Error: {mse_rounded}')\n",
    "# print(f'Random Forest. R²: {r2_rounded}')\n",
    "# print(f'Random Forest. Mean Absolute Error: {mae_rounded}')"
   ],
   "id": "42686403ab2910a0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
